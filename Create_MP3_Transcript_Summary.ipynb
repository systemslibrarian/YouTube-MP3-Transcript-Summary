{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p3DR51xwA0p"
   },
   "source": [
    "YouTube Video Transcriber and Summarizer (Single Cell)\n",
    "This Google Colab notebook allows you to download the audio from a YouTube video, transcribe it using faster-whisper, and then summarize the transcript using OpenAI's GPT-4 model. All necessary installations and code are combined into one executable block.\n",
    "\n",
    "Instructions:\n",
    "Set Your OpenAI API Key: Before running the code, you must set your OPENAI_API_KEY using Colab's \"Secrets\" feature.\n",
    "\n",
    "On the left sidebar in Colab, click the \"key\" icon (Secrets).\n",
    "\n",
    "Click \"Add new secret\".\n",
    "\n",
    "For \"Name\", enter OPENAI_API_KEY.\n",
    "\n",
    "For \"Value\", paste your actual OpenAI API key.\n",
    "\n",
    "Check \"Notebook access\" for this notebook.\n",
    "\n",
    "Update YouTube URL: In the code cell below, replace the youtube_url variable with the actual URL of the YouTube video you want to summarize.\n",
    "\n",
    "Configure Audio Removal: Set remove_audio_after_processing to True or False based on whether you want to keep the downloaded audio file.\n",
    "\n",
    "Run the Cell: Click the \"Play\" button next to the code cell, or press Shift + Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cRsXdsf0Sb0"
   },
   "source": [
    "Hugging Face plays a role in this script through the faster_whisper library.\n",
    "\n",
    "Specifically, faster_whisper uses the Hugging Face Hub to:\n",
    "\n",
    "Download the Whisper AI model: When you initialize model = WhisperModel(\"base\", ...) for the first time, faster_whisper connects to the Hugging Face Hub to download the \"base\" Whisper model files (like tokenizer.json, vocabulary.txt, model.bin, config.json). These are the large files that contain the actual transcription model.\n",
    "\n",
    "So, while you don't directly interact with Hugging Face in your code, faster_whisper relies on it as the repository for the pre-trained Whisper models it uses for audio transcription. The warning you saw about HF_TOKEN is just a general message from the huggingface_hub library, indicating that it could use a token for certain operations, but it's not required for public model downloads like the \"base\" Whisper model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0f7405709dcb4e208bd87e0b24160b93",
      "8984cff49f5d47228968bf655a611e7f",
      "6f8845eaa3254922af6563658223a241",
      "5cdbe5f6bad8456fbabd1f754230270a",
      "df1d0ee8a0484367802ccee98d7edd86",
      "df0c912b5a4b4e239270370040dc66c9",
      "697e941884ed48a591078b6201c28d1f",
      "d006817c575841faa50d389754672be3",
      "96869602c9474675bafc798da5881287",
      "ecdc2565f1894988a4ae603d7b6d4d3f",
      "6266b2ce38e34f79ab13e66b7706c9e6",
      "ac6edf42bd1e4ae3ae12083901d9bef7",
      "81c2fd24a21d432cb609bbe86983d1d1",
      "a665d58b311c4f9f819c38c370f7166a",
      "f8e760cfbe8b4fd1a657da5b666f0239",
      "cc669fba58b2469ea47dce21803f66c9",
      "a866591a9d1e4efba1bbc74417798391",
      "ab03570d509748d1891211382c1b73fb",
      "446359a86d56439faf11f0e3d8c2927c",
      "4b9c8fa895b6475aa3168db944c570b2",
      "d66de52bd1f942cc813899793a164232",
      "d378c10a5f2a43758c860c7f11e3b60c",
      "ed6d6fe0e0a046dc8f6ffd1a5d69a179",
      "01c75bf235d34c8488b18d72cae53a26",
      "42475eccfc714f089e0699bf2a29b01d",
      "2ec5a663e26f4095a8c5f2dbd85ab73f",
      "e8bfcf81785340da9cb016f620656c13",
      "95858f0107e54a928f7e98ff0a57a4f0",
      "a831dc4206ee406b92e02217801edebc",
      "f9bd5912d83f4f0d971b02a9300a1083",
      "d54dcf5bec8442b19fc3c122bc92f1ce",
      "db46e33deca74dec9f5fa6bd4969c053",
      "cdaa53670e064f63a894dce658727120",
      "0bcd4db8bd574802816a872b4fa460f6",
      "8e452846593247439af1882e32fe1c7d",
      "15bf586fac0d425caada505094574eba",
      "cef5ede53e884d97a7d174bec2598ca6",
      "a960d6be02c44d7e9ed2030855462eb7",
      "865fa6d7ee024349ae3ac60977b09f3b",
      "0cb505293bf540d38147b6ee758683b7",
      "9f871e67c747425296217cf36c45f185",
      "72598461afa74d06828ebdd199fef957",
      "b14022c314174264933a6934f6a3a200",
      "91b43dafeb45437cbc2b653e8187dddb"
     ]
    },
    "id": "aG6rTQYk6AC2",
    "outputId": "a500b950-2d24-46f9-dedb-384b617b2fac"
   },
   "outputs": [],
   "source": [
    "# --- SECTION 1: Install Dependencies ---\n",
    "# This installs yt-dlp (for downloading), faster-whisper (for transcription), and openai (for summarization).\n",
    "!pip install yt-dlp faster-whisper openai\n",
    "\n",
    "# Install FFmpeg: yt-dlp uses ffmpeg to extract audio from video files.\n",
    "!apt-get install ffmpeg -y\n",
    "\n",
    "# --- SECTION 2: Configuration - Set Your OpenAI API Key ---\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Attempt to get the API key from Colab Secrets first\n",
    "try:\n",
    "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
    "except userdata.SecretNotFoundError:\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY not found in Colab Secrets. \"\n",
    "        \"Please set it following the instructions in the markdown cell above.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Fallback to environment variable if not found in secrets (e.g., if running outside Colab)\n",
    "if not openai_api_key:\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found. Please set it in Colab Secrets or as an environment variable.\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key # Set it as an environment variable for the script\n",
    "print(\"OpenAI API Key loaded.\")\n",
    "\n",
    "\n",
    "# --- SECTION 3: Application Logic ---\n",
    "import openai\n",
    "import subprocess\n",
    "from faster_whisper import WhisperModel\n",
    "import logging\n",
    "import textwrap # Import textwrap for formatting output\n",
    "\n",
    "# Configure logging to see more details\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def download_audio(url: str, output_filename=\"audio.mp3\"):\n",
    "    \"\"\"\n",
    "    Downloads audio from a given YouTube URL using yt-dlp and saves it as an MP3.\n",
    "    Requires yt-dlp and ffmpeg to be installed.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Attempting to download audio from: {url}\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"yt-dlp\", \"--extract-audio\", \"--audio-format\", \"mp3\", url, \"-o\", output_filename],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True # Raise an exception for non-zero exit codes\n",
    "        )\n",
    "        logging.info(f\"Download stdout: {result.stdout}\")\n",
    "        logging.info(f\"Download stderr: {result.stderr}\")\n",
    "        logging.info(f\"Audio downloaded to: {output_filename}\")\n",
    "        return output_filename\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(f\"Error during audio download: {e}\")\n",
    "        logging.error(f\"Stdout: {e.stdout}\")\n",
    "        logging.error(f\"Stderr: {e.stderr}\")\n",
    "        raise\n",
    "    except FileNotFoundError:\n",
    "        logging.error(\"yt-dlp or ffmpeg not found. Ensure they are installed in the Colab environment.\")\n",
    "        raise\n",
    "\n",
    "def transcribe_audio(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Transcribes an audio file using the Faster Whisper model.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Starting transcription of: {file_path}\")\n",
    "    try:\n",
    "        # Load the Whisper model. \"base\" is a good starting point for speed.\n",
    "        # You can try \"small\", \"medium\", or \"large\" for better accuracy if needed.\n",
    "        # Using device=\"cpu\" and compute_type=\"int8\" for broader compatibility in Colab's free tier.\n",
    "        model = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "        # Transcribe the audio file\n",
    "        segments, info = model.transcribe(file_path, beam_size=5)\n",
    "\n",
    "        transcript_parts = []\n",
    "        for segment in segments:\n",
    "            transcript_parts.append(segment.text)\n",
    "            # You can uncomment the line below to see segment-by-segment transcription\n",
    "            # logging.info(f\"[ {segment.start:.2f}s -> {segment.end:.2f}s ] {segment.text}\")\n",
    "\n",
    "        full_transcript = \" \".join(transcript_parts)\n",
    "        logging.info(\"Transcription complete.\")\n",
    "        return full_transcript\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during audio transcription: {e}\")\n",
    "        raise\n",
    "\n",
    "def summarize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the given text using OpenAI's GPT-4 model.\n",
    "    Requires OPENAI_API_KEY to be set as an environment variable.\n",
    "    \"\"\"\n",
    "    logging.info(\"Attempting to summarize text using OpenAI.\")\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY') # Retrieve from environment variable\n",
    "    if not openai_api_key:\n",
    "        raise ValueError(\"OPENAI_API_KEY environment variable not set. Please set it.\")\n",
    "\n",
    "    try:\n",
    "        client = openai.OpenAI(api_key=openai_api_key)\n",
    "        prompt = f\"Summarize the following podcast transcript:\\n\\n{text}\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\", # Using GPT-4 as requested\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        summary = response.choices[0].message.content\n",
    "        logging.info(\"Text summarization complete.\")\n",
    "        return summary\n",
    "    except openai.APIError as e:\n",
    "        logging.error(f\"OpenAI API error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred during summarization: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- SECTION 4: Run the Summarizer ---\n",
    "\n",
    "# IMPORTANT: Replace this with the actual YouTube video URL you want to process\n",
    "youtube_url = \"https://www.youtube.com/watch?v=AOi-wYOqs3E\" # Example\n",
    "# Define the output audio file path\n",
    "audio_file_path = \"downloaded_audio.mp3\"\n",
    "transcript_file_path = \"transcript.txt\" # Path for the transcript file\n",
    "summary_file_path = \"summary.txt\" # NEW: Path for the summary file\n",
    "\n",
    "# OPTION: Set to True to remove the audio file after processing, False to keep it.\n",
    "remove_audio_after_processing = False\n",
    "\n",
    "try:\n",
    "    # 1. Download audio\n",
    "    downloaded_file = download_audio(youtube_url, audio_file_path)\n",
    "\n",
    "    # 2. Transcribe audio\n",
    "    transcript = transcribe_audio(downloaded_file)\n",
    "\n",
    "    # Save transcript to a file\n",
    "    with open(transcript_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(transcript)\n",
    "    logging.info(f\"Transcript saved to: {transcript_file_path}\")\n",
    "\n",
    "    # 3. Summarize transcript\n",
    "    summary = summarize_text(transcript)\n",
    "\n",
    "    # NEW: Save summary to a file\n",
    "    with open(summary_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(summary)\n",
    "    logging.info(f\"Summary saved to: {summary_file_path}\")\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    # Wrap the summary text for better readability\n",
    "    wrapped_summary = textwrap.fill(summary, width=80) # Adjust width as needed\n",
    "    print(wrapped_summary)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during the process: {e}\")\n",
    "finally:\n",
    "    # Optional cleanup for the audio file based on the new variable\n",
    "    if remove_audio_after_processing and os.path.exists(audio_file_path):\n",
    "        os.remove(audio_file_path)\n",
    "        logging.info(f\"Cleaned up {audio_file_path}\")\n",
    "    else:\n",
    "        logging.info(f\"Audio file ({audio_file_path}) will remain in your Colab environment.\")\n",
    "\n",
    "    # Transcript file will always remain\n",
    "    logging.info(f\"Transcript file ({transcript_file_path}) will remain in your Colab environment.\")\n",
    "\n",
    "    # Summary file will always remain\n",
    "    logging.info(f\"Summary file ({summary_file_path}) will remain in your Colab environment.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
